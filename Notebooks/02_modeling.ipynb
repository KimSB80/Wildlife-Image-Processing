{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cc14a2c-3a15-4ca4-a5e5-ef0492c931af",
   "metadata": {},
   "source": [
    "## Modeling with CNN for Wildlife Image Classification\n",
    "\n",
    "The data for this project is sourced from https://www.kaggle.com/datasets/akash2907/bird-species-classification "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaa4810-3fbd-4e84-b6f8-bb6d9a117b0b",
   "metadata": {},
   "source": [
    "### 1. Import Packages and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8fdf750-4fb5-4ee4-8b99-16375dd6b717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import imageio.v2 as imageio\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db0788ed-89fe-4059-b871-a550a8e713dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2409d88f-5715-4b23-9877-3babbab9234c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path and folder names\n",
    "train_path = \"../jpeg/train\"\n",
    "test_path = \"../jpeg/test\"\n",
    "\n",
    "folder_names = os.listdir(train_path)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "666111fb-8edf-4b70-adcf-6523c95597ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n"
     ]
    }
   ],
   "source": [
    "# load images\n",
    "\n",
    "# Create lists to store image data and labels\n",
    "image_data=[]\n",
    "image_labels = []\n",
    "\n",
    "for folder in folder_names:\n",
    "    img_path = os.path.join(train_path, folder) \n",
    "    \n",
    "    for filename in os.listdir(img_path):\n",
    "        if filename.endswith((\".jpg\",\".JPG\")):\n",
    "            img = imageio.imread(os.path.join(img_path, filename))\n",
    "            img = cv2.resize(img, (300, 300)) #resize\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY ) #convert to grayscale\n",
    "\n",
    "            image_data.append(img)\n",
    "            image_labels.append(folder)\n",
    "\n",
    "# Convert data to numpy array\n",
    "image_data = np.array(image_data)\n",
    "print(\"success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69145a76-63d4-44f3-b51f-ec7837cf9f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train array: (149, 300, 300)\n",
      "Shape of x_train labels: 149\n"
     ]
    }
   ],
   "source": [
    "print('Shape of x_train array:', x_train.shape)\n",
    "print('Shape of x_train labels:', len(image_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f1f1c8-0674-4729-9f6b-5f68ad16334f",
   "metadata": {},
   "source": [
    "#### Get the label mappings\n",
    "The labels dictionary matches class names against the label indices used for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c454503e-663a-44c9-895d-2f8dd4f63e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to map image names to their corresponding integer labels\n",
    "name_to_label = {name: label for label, name in enumerate(folder_names)}\n",
    "\n",
    "# Create a list to store the integer labels for each image\n",
    "integer_labels = []\n",
    "\n",
    "# Loop through the list of image names and assign the corresponding integer label\n",
    "for name in image_labels:\n",
    "    label = name_to_label.get(name)\n",
    "    if label is not None:\n",
    "        integer_labels.append(label)\n",
    "    else:\n",
    "        # Handle the case when the image name is not found in the mapping\n",
    "        # Here, we'll set it to -1 to indicate an unknown label\n",
    "        integer_labels.append(-1)\n",
    "\n",
    "# Print the list of integer labels\n",
    "#print(integer_labels)\n",
    "print(len(integer_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d151bf4a-3d6e-49f3-a8e8-297203c94d6a",
   "metadata": {},
   "source": [
    "### Build base model\n",
    "First, we need to one-hot-encode the target variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7ee54166-34bc-45c9-8b94-e7a59980569e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f8ada13-7db2-4c00-ba91-0a13c1fbb360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(149, 16)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert labels to one-hot encoded vectors\n",
    "num_classes = 16  \n",
    "one_hot_labels = to_categorical(integer_labels, num_classes=num_classes)\n",
    "\n",
    "# Print the one-hot encoded labels\n",
    "print(one_hot_labels)\n",
    "one_hot_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04609cd-4f0c-4b75-aecb-dd76befb4f9b",
   "metadata": {},
   "source": [
    "### 2. Load Data and Apply Augmentations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840c7cb2-3e94-4326-8bfc-ce2fddfbf7ad",
   "metadata": {},
   "source": [
    "Loading the training dataset and applying augmentations using ImageDataGenerator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e12f4b1d-fe18-439f-8b27-8bea626e67ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the image and batch size\n",
    "image_size = (150, 150)\n",
    "batch_size = 32\n",
    "\n",
    "# Number of classes\n",
    "num_classes = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "844bb0ec-a883-4ee9-9fee-24220d7809dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 123 images belonging to 16 classes.\n",
      "Found 26 images belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create an ImageDataGenerator for data augmentation and preprocessing\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,      # Normalize pixel values to [0, 1]\n",
    "#    rotation_range=20,      # Randomly rotate images within the range of 20 degrees\n",
    "#    width_shift_range=0.1,  # Randomly shift images horizontally within 10% of the image width\n",
    "#    height_shift_range=0.1, # Randomly shift images vertically within 10% of the image height\n",
    "#    horizontal_flip=True,   # Randomly flip images horizontally\n",
    "    validation_split=0.2    # Split the data into 80% for training and 20% for validation\n",
    ")\n",
    "\n",
    "# Load and preprocess images from the directory\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',  # Set to 'categorical' for one-hot encoded labels\n",
    "    subset='training'          # Use the training subset of your data\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',  # Set to 'categorical' for one-hot encoded labels\n",
    "    subset='validation'        # Use the validation subset of your data\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d734e09c-f825-47e7-b1d9-0b6d0ee47d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1 (Conv2D)           (None, 146, 146, 32)      2432      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 73, 73, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 170528)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               21827712  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                2064      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21832208 (83.28 MB)\n",
      "Trainable params: 21832208 (83.28 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add a 2D Convolutional layer\n",
    "model.add(Conv2D(32, kernel_size=(5, 5), padding='valid', activation='relu', input_shape=(image_size[0], image_size[1], 3)))\n",
    "\n",
    "# Add a MaxPooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Add more Conv2D and MaxPooling2D layers as needed later ...\n",
    "\n",
    "# Flatten the output from Convolutional layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add a fully connected Dense layer\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "# Add the final Dense layer with softmax activation for multi-class classification\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model architecture\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d347c6bd-3e54-4483-bc88-89bbe9a0f446",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g0/vdx5n5rj5w9979hjrlxdpkv40000gn/T/ipykernel_10345/1120869770.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 [==============================] - 12s 4s/step - loss: 23.4974 - accuracy: 0.0440\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 9s 3s/step - loss: 9.9993 - accuracy: 0.1868\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 9s 3s/step - loss: 5.3272 - accuracy: 0.2292\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 9s 3s/step - loss: 3.0093 - accuracy: 0.1978\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 8s 3s/step - loss: 2.2469 - accuracy: 0.3187\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 9s 3s/step - loss: 1.9515 - accuracy: 0.5165\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 9s 3s/step - loss: 1.7979 - accuracy: 0.6484\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 9s 3s/step - loss: 1.5764 - accuracy: 0.6044\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 9s 3s/step - loss: 1.3232 - accuracy: 0.6484\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.9691 - accuracy: 0.7253\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2c6179d50>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60f6442-64be-48c1-adce-83ff7812542c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
